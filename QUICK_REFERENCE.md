# âš¡ Quick Reference Card

## ğŸš€ Start Here

```bash
# Activate environment
source .venv/bin/activate

# Run app
./iniciar.sh

# Run tests
python test_tavily_integration.py
```

## ğŸ”§ Configuration

### Get API Key
- **Tavily** (recommended): https://tavily.com
- **Grok**: https://console.x.ai
- **Gemini**: https://aistudio.google.com/app/apikey

### Set API Key
```bash
# Copy template
cp .env.local.example .env.local

# Edit with your key
nano .env.local
```

### Switch Provider
```bash
# Edit .env
ONLINE_SEARCH_PROVIDER=tavily  # or grok, gemini, lmstudio

# Restart app
./iniciar.sh
```

## ğŸ“Š Architecture at a Glance

```
PDF â†’ 16 Workers â†’ phi3:mini LLM â†’ Missing fields?
                                      â†“
                              Online Search (Tavily/Grok/Gemini)
                                      â†“
                              DuckDB (thread-safe) â†’ Results Tab
```

## ğŸ¯ Providers

| Provider | Setup | Cost | Speed | Notes |
|----------|-------|------|-------|-------|
| **Tavily** | API key (free) | 100 searches/mo | 2-5s | âœ… Recommended |
| **Grok** | API key (free) | Unlimited | 3-7s | No quota limits |
| **Gemini** | API key (free) | Limited | 1-3s | Quota-limited |
| **LM Studio** | None | Free | 5-10s | Local fallback |

## ğŸ“ Important Files

```
config:
  .env                    (provider setting)
  .env.local             (API keys - NEVER COMMIT)
  src/utils/config.py    (env loading)

clients:
  src/core/llm_client.py (4 client classes)

app:
  src/gui/main_app.py    (UI + provider selection)

database:
  src/database/duckdb_manager.py (THREAD-SAFE with lock)

tests:
  test_tavily_integration.py (6 tests, all passing)
```

## ğŸ”’ Thread Safety

âŒ **Wrong:**
```python
self.connection.execute(query)  # NOT SAFE
```

âœ… **Correct:**
```python
with self._lock:
    self.connection.execute(query)  # SAFE for 16 workers
```

## ğŸ§ª Run Tests

```bash
# Integration tests
python test_tavily_integration.py

# Expected: 6/6 PASS
```

## ğŸ“ Common Edits

### Change Worker Count
```env
# .env
MAX_WORKERS=16  # or 8, 4, 2
```

### Change LLM Model
```env
# .env
LM_STUDIO_MODEL=phi3:mini  # or llama2, mistral, etc
```

### Change Search Provider
```env
# .env
ONLINE_SEARCH_PROVIDER=tavily  # tavily, grok, gemini, lmstudio
```

### Add New Field to Extract
1. Edit `src/core/document_processor.py`
2. Add to `ADDITIONAL_FIELDS` list
3. Update field translations in TavilyClient
4. Update database schema

## ğŸš¨ Critical Notes

âš ï¸ **Thread Safety:** DuckDB uses `threading.Lock()` - essential for 16 workers
âš ï¸ **API Keys:** Never commit `.env` or `.env.local`
âš ï¸ **GUI Thread:** All UI updates must use `.after()` for main thread
âš ï¸ **Progress Bar:** Must call `show_progress()` before processing

## ğŸ› Debug Commands

```bash
# Check provider
python -c "from src.utils.config import ONLINE_SEARCH_PROVIDER; print(ONLINE_SEARCH_PROVIDER)"

# Check config loaded
python -c "from src.utils.config import TAVILY_CONFIG; print('âœ… Tavily API key' if TAVILY_CONFIG.get('api_key') else 'âŒ No key')"

# Check DB
python -c "from src.database.duckdb_manager import DuckDBManager; db = DuckDBManager(); print(db.db.execute('SELECT COUNT(*) FROM documents').fetchall())"

# View logs
tail -f data/logs/app.log
```

## ğŸ“Š Status Bar Messages

```
"LLM local conectado. | Tavily pronto para pesquisa online."  âœ…
"LLM local conectado. | Grok pronto para pesquisa online."    âœ…
"LLM local nao respondeu."                                     âŒ
```

## ğŸ”„ Processing Flow

```
start_processing()
    â†“
show_progress(total)
    â†“
enqueue files Ã— total
    â†“
workers (parallel):
  extract_pdf()
    â†’ llm_extract()
      â†’ online_search() [if missing fields]
        â†’ store_in_db() [THREAD-SAFE]
          â†’ update_progress()
    â†“
all done?
    â†“
hide_progress()
â†’ show results_tab
```

## ğŸ¨ GUI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš™ï¸ ConfiguraÃ§Ã£o | âš¡ Processamento | ğŸ“Š Resultados â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Folder selector                 â”‚
â”‚ LLM Status: "...pronto"         â”‚
â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 45%    [â¹ï¸ Cancel]  â”‚  â† Progress bar
â”‚ File list (scrollable)          â”‚
â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status: Ready - Connections verified â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ Recent Commits

```
0be84ca Add Copilot/Codex context guide
65ebc7b Add comprehensive session summary
a3c7603 Add Tavily AI search integration â† Latest major feature
```

## ğŸ”— Key Classes

```python
# Clients (all support same interface)
LMStudioClient()    â†’ local LLM search
TavilyClient()      â†’ online search
GrokClient()        â†’ online search
GeminiClient()      â†’ online search

# Database
DuckDBManager()     â†’ stores all results (thread-safe)

# Processing
DocumentProcessor   â†’ orchestrates extraction
ProcessingQueue     â†’ manages 16 workers

# GUI
Application         â†’ main window
SetupTab            â†’ folder/progress
ProcessingTab       â†’ status display
ResultsTab          â†’ results table
```

## ğŸ’¾ Data Model

```python
{
    "field_name": {
        "value": "extracted_value",
        "confidence": 0.0-1.0,  # 0.8=answer, 0.6=snippet, 0.0=not found
        "context": "source info"
    }
}
```

## ğŸ†˜ Common Issues

| Problem | Fix |
|---------|-----|
| App won't start | `pip install -r requirements.txt` |
| Progress bar hidden | `app.setup_tab.show_progress(total)` before processing |
| Workers hang | Check `LM_STUDIO_TIMEOUT` in .env |
| No API key error | Add to `.env.local`, not `.env` |
| Database locked | Restart app (only 1 writer allowed) |
| "Provider not found" | Set `ONLINE_SEARCH_PROVIDER=tavily` in .env |

## ğŸ“ Where to Find Things

**"How do I..."**

| Question | File | Line |
|----------|------|------|
| Add a new search provider? | src/core/llm_client.py | 432 (TavilyClient example) |
| Change how progress shows? | src/gui/main_app.py | 1237 |
| Add a field to extract? | src/core/document_processor.py | DEFAULT_FIELDS |
| Fix thread issues? | src/database/duckdb_manager.py | 30 (Lock init) |
| See all config? | src/utils/config.py | 87-138 |
| Understand processing? | src/core/queue_manager.py | - |

---

**Status:** âœ… All systems ready
**Last Updated:** 2025-11-18
**Total Lines:** 7,000+ (production ready)
