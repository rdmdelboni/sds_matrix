# ğŸ¤– Copilot/Codex Context Guide

**Quick reference for AI assistants working on this project.**

## ğŸ“‹ Project Overview

**FDS-2-Matrix** - Extract chemical product data from PDF Safety Data Sheets (SDS)

- **Language:** Python 3.13+
- **GUI:** Tkinter (ttk)
- **Database:** DuckDB (local SQLite-like)
- **LLM:** phi3:mini (via Ollama/LM Studio)
- **Online Search:** Tavily/Grok/Gemini APIs

## ğŸ¯ Current State (Session: 2025-11-18)

### Features Implemented âœ…
1. Multi-threaded PDF processing (16 workers)
2. Local LLM extraction (phi3:mini)
3. Online search providers (Tavily, Grok, Gemini, LM Studio)
4. Integrated progress bar in GUI
5. Secure API key management (.env.local)
6. DuckDB with thread-safe locking
7. Results export (CSV, Excel)

### Recent Changes
- **Latest Commit:** `65ebc7b` - Add session summary
- **Previous:** `a3c7603` - Tavily integration
- **Before:** Progress bar integration, API key management, thread safety

## ğŸ“‚ Critical Files

### Core Logic
```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_client.py           # 4 clients: LMStudio, Tavily, Grok, Gemini
â”‚   â”œâ”€â”€ document_processor.py   # PDF extraction pipeline
â”‚   â”œâ”€â”€ chunk_strategy.py       # Text chunking logic
â”‚   â””â”€â”€ queue_manager.py        # Async job queue (16 workers)
â”œâ”€â”€ database/
â”‚   â””â”€â”€ duckdb_manager.py       # THREAD-SAFE: Uses threading.Lock()
â”œâ”€â”€ gui/
â”‚   â””â”€â”€ main_app.py             # Tkinter app, provider selection
â””â”€â”€ utils/
    â”œâ”€â”€ config.py               # ENV loading + provider detection
    â””â”€â”€ logger.py               # Structured logging
```

### Configuration
```
.env                    # Shared (committed): Provider choice, LM Studio settings
.env.local             # Private (git-ignored): API keys
.env.local.example     # Template for users
```

### Documentation
```
SESSION_SUMMARY.md     # â† Read this first (418 lines)
TAVILY_SETUP.md        # Tavily-specific setup (331 lines)
GEMINI_SETUP.md        # Gemini setup (original)
INTEGRATED_PROGRESS_BAR.md
```

## ğŸ”‘ Key Concepts

### 1. Provider System
```python
# Automatic detection in config.py
ONLINE_SEARCH_PROVIDER = detect_provider():
    # Try in order:
    if TAVILY_API_KEY: return "tavily"
    elif GROK_API_KEY: return "grok"
    elif GOOGLE_API_KEY: return "gemini"
    else: return "lmstudio"
```

### 2. Thread Safety
```python
# In DuckDBManager.__init__()
self._lock = threading.Lock()

# All DB operations wrapped:
with self._lock:
    self.connection.execute(...)  # SAFE for 16 parallel workers
```

### 3. Client Interface
```python
class AnyClient:
    def test_connection(self) -> bool:
        """Check if API configured"""

    def search_online_for_missing_fields(
        product_name: str | None,
        cas_number: str | None,
        un_number: str | None,
        missing_fields: list[str]
    ) -> Dict[str, Dict[str, object]]:
        # Returns: {"field": {"value": "...", "confidence": 0.0-1.0, "context": "..."}}
```

### 4. Processing Flow
```
User selects PDFs
    â†“
start_processing()
    â”œâ”€ Show progress bar
    â””â”€ Enqueue files (ProcessingQueue)
        â†“
        16 workers (parallel):
        â”œâ”€ Extract text from PDF
        â”œâ”€ Local LLM extraction (phi3:mini)
        â”œâ”€ If missing fields â†’ Online search (Tavily/Grok/etc)
        â”œâ”€ Merge results + confidence scores
        â””â”€ Store in DuckDB (THREAD-SAFE)
            â†“
        Status updates â†’ UI progress bar
            â†“
Hide progress bar
    â†“
Show results in "Resultados" tab
```

## ğŸ”§ Common Tasks

### Add New Online Search Provider
```python
# 1. Create client class in src/core/llm_client.py
class MyClient:
    def __init__(self):
        self.api_key = str(MY_CONFIG.get("api_key", ""))

    def test_connection(self) -> bool:
        return bool(self.api_key)

    def search_online_for_missing_fields(...):
        # Implement search logic
        return results

# 2. Add config in src/utils/config.py
MY_CONFIG = {
    "api_key": os.getenv("MY_API_KEY", ""),
    ...
}

# 3. Update ONLINE_SEARCH_PROVIDER priority
ONLINE_SEARCH_PROVIDER = os.getenv(
    "ONLINE_SEARCH_PROVIDER",
    "my_provider" if os.getenv("MY_API_KEY") else ...
)

# 4. Update Application in src/gui/main_app.py
elif provider == "my_provider":
    self.online_search_client = MyClient()

# 5. Update status check
elif provider_name == "my_provider":
    status += " | MyProvider ready"
```

### Change Processing Configuration
```python
# In .env:
MAX_WORKERS=16              # Parallel workers
CHUNK_SIZE=2000             # Text chunk size
LM_STUDIO_MODEL=phi3:mini   # LLM model
LM_STUDIO_TEMPERATURE=0.0   # Extraction precision
```

### Debug Issues
```bash
# Check configuration
python -c "from src.utils.config import *; print(f'Provider: {ONLINE_SEARCH_PROVIDER}')"

# Run tests
python test_tavily_integration.py

# Check logs
tail -f data/logs/app.log

# Verify database
python -c "from src.database.duckdb_manager import DuckDBManager; db = DuckDBManager(); print(db.db.execute('SELECT COUNT(*) FROM documents').fetchall())"
```

### Add New Field to Extract
1. Add to `ADDITIONAL_FIELDS` in `src/core/document_processor.py`
2. Update field_translations in TavilyClient (for online search)
3. Add to database schema in DuckDBManager
4. Update UI in ResultsTab

## ğŸš¨ Important Notes

### âš ï¸ Thread Safety CRITICAL
- **NEVER** access DuckDB outside `with self._lock:` block
- All database operations in `duckdb_manager.py` are protected
- 16 workers depend on this

### âš ï¸ API Keys CRITICAL
- Never commit `.env` or `.env.local`
- Always use `.env.local` for user's keys
- .gitignore already has protection

### âš ï¸ GUI Thread Safety
- All UI updates must happen on main thread
- Use `queue.Queue` for worker â†’ UI communication
- Progress bar updates use `self.after()` for main thread

## ğŸ§ª Running Tests

```bash
# Tavily integration tests
source .venv/bin/activate
python test_tavily_integration.py

# Expected output:
# âœ… Imports
# âœ… Configuration
# âœ… Client Instantiation
# âœ… Tavily Connection
# âœ… Provider Selection
# âœ… Application Initialization
```

## ğŸ“Š Code Statistics

```
Total: ~7,000 lines of code

Core processing:
â”œâ”€â”€ llm_client.py: 560 lines (4 clients)
â”œâ”€â”€ document_processor.py: ~500 lines
â”œâ”€â”€ queue_manager.py: ~200 lines
â”œâ”€â”€ duckdb_manager.py: ~300 lines

GUI:
â”œâ”€â”€ main_app.py: ~1,500 lines (3 tabs)
â”œâ”€â”€ Styles: ~100 lines

Config/Utils:
â”œâ”€â”€ config.py: ~145 lines
â”œâ”€â”€ logger.py: ~50 lines
â”œâ”€â”€ file_utils.py: ~100 lines
```

## ğŸ”— Key Dependencies

```
Python: 3.13+
â”œâ”€â”€ tkinter           # GUI (built-in)
â”œâ”€â”€ duckdb            # Database
â”œâ”€â”€ openai (SDK)      # LM Studio client
â”œâ”€â”€ httpx             # HTTP requests (Tavily, Grok, Gemini)
â”œâ”€â”€ python-dotenv     # .env loading
â””â”€â”€ pytesseract       # OCR for scanned PDFs

External Services:
â”œâ”€â”€ Ollama/LM Studio  # Local LLM (phi3:mini)
â”œâ”€â”€ Tavily API        # Online search (recommended)
â”œâ”€â”€ Grok API          # Alternative search
â””â”€â”€ Gemini API        # Alternative search
```

## ğŸ’¾ Database Schema

```sql
documents (id, file_path, status, created_at, updated_at)
extractions (id, document_id, field_name, value, confidence, source, created_at)
field_details (id, document_id, field_name, value, confidence, context, created_at)
```

## ğŸ¨ UI Structure

```
Application (Tkinter)
â”œâ”€â”€ Notebook (3 tabs)
â”‚   â”œâ”€â”€ âš™ï¸ ConfiguraÃ§Ã£o (SetupTab)
â”‚   â”‚   â”œâ”€â”€ Folder selector
â”‚   â”‚   â”œâ”€â”€ LLM Status bar
â”‚   â”‚   â”œâ”€â”€ Progress bar (integrated)
â”‚   â”‚   â””â”€â”€ File list
â”‚   â”œâ”€â”€ âš¡ Processamento (ProcessingTab)
â”‚   â”‚   â”œâ”€â”€ Processing status grid
â”‚   â”‚   â”œâ”€â”€ Field details
â”‚   â”‚   â””â”€â”€ Real-time updates
â”‚   â””â”€â”€ ğŸ“Š Resultados (ResultsTab)
â”‚       â”œâ”€â”€ Results table
â”‚       â”œâ”€â”€ Filters
â”‚       â””â”€â”€ Export buttons
â””â”€â”€ Status bar (bottom)
    â””â”€â”€ Current status + version
```

## ğŸš€ Quick Start Commands

```bash
# Setup
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Run
./iniciar.sh

# Test
python test_tavily_integration.py

# Configure
cp .env.local.example .env.local
nano .env.local  # Add API key
```

## ğŸ“Œ Git Commits This Session

```
65ebc7b Add comprehensive session summary for reference
a3c7603 Add Tavily AI search integration for online field lookup
f9adfc9 Add progress bar demonstration script
2d8909f Fix progress bar visibility and layout issues
b34a12e Move progress bar from external dialog to integrated interface
4ff5fab Add secure API key configuration with .env.local support
```

## ğŸ†˜ Troubleshooting

| Issue | Solution |
|-------|----------|
| "Bus error (core dumped)" | Update DuckDBManager with threading.Lock() (already fixed) |
| Progress bar not showing | Ensure SetupTab.show_progress() called before processing |
| API key not loading | Check .env.local exists and readable (not git-ignored) |
| "Provider not found" | Set ONLINE_SEARCH_PROVIDER in .env |
| 16 workers timeout | Increase LM_STUDIO_TIMEOUT in .env |
| DuckDB locked | Restart app (only one instance can write) |

## ğŸ“ Quick Reference

**Files to modify when:**
- Adding feature â†’ `src/core/` or `src/gui/`
- Changing config â†’ `src/utils/config.py` and `.env`
- Adding provider â†’ `src/core/llm_client.py`, `src/gui/main_app.py`
- Bug fix â†’ Fix + add test to `test_*.py`
- Documentation â†’ Update `SESSION_SUMMARY.md` and `.md` files

**Always:**
1. Run tests before committing
2. Update SESSION_SUMMARY.md with major changes
3. Check thread safety with DuckDB
4. Never commit .env or .env.local
5. Use git commit messages with [Claude Code] signature

---

**Last Updated:** 2025-11-18
**For:** Claude Code, GitHub Copilot, other AI assistants
**Status:** Ready for continuation âœ…
